{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58193612-eea3-4de1-b951-2265315e527c",
   "metadata": {},
   "source": [
    "Данные взяты отсюда: https://www.kaggle.com/datasets/microize/newyork-yellow-taxi-trip-data-2020-2019/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e58a787-fdb2-4610-b745-0dbaa976ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, DataFrame, types\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3ff1fa-13ca-40dc-b92d-9befa79fb8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/11 19:04:37 WARN Utils: Your hostname, MacBook-Pro-Eva.local resolves to a loopback address: 127.0.0.1; using 10.1.5.116 instead (on interface en0)\n",
      "24/11/11 19:04:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/11 19:04:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e95c5abd-fd9f-48c0-9d9f-d134936c047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"data/csv/yellow_tripdata_2020-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9f9e874-12b3-4a77-910b-a34fab703b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       1| 2020-01-01 00:28:15|  2020-01-01 00:33:03|              1|         1.20|         1|                 N|         238|         239|           1|          6|    3|    0.5|      1.47|           0|                  0.3|       11.27|                 2.5|\n",
      "|       1| 2020-01-01 00:35:39|  2020-01-01 00:43:04|              1|         1.20|         1|                 N|         239|         238|           1|          7|    3|    0.5|       1.5|           0|                  0.3|        12.3|                 2.5|\n",
      "|       1| 2020-01-01 00:47:41|  2020-01-01 00:53:52|              1|          .60|         1|                 N|         238|         238|           1|          6|    3|    0.5|         1|           0|                  0.3|        10.8|                 2.5|\n",
      "|       1| 2020-01-01 00:55:23|  2020-01-01 01:00:14|              1|          .80|         1|                 N|         238|         151|           1|        5.5|  0.5|    0.5|      1.36|           0|                  0.3|        8.16|                   0|\n",
      "|       2| 2020-01-01 00:01:58|  2020-01-01 00:04:16|              1|          .00|         1|                 N|         193|         193|           2|        3.5|  0.5|    0.5|         0|           0|                  0.3|         4.8|                   0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9adbf4af-56bf-4d4e-8b6c-6e9ed41f22c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', StringType(), True), StructField('tpep_pickup_datetime', StringType(), True), StructField('tpep_dropoff_datetime', StringType(), True), StructField('passenger_count', StringType(), True), StructField('trip_distance', StringType(), True), StructField('RatecodeID', StringType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', StringType(), True), StructField('DOLocationID', StringType(), True), StructField('payment_type', StringType(), True), StructField('fare_amount', StringType(), True), StructField('extra', StringType(), True), StructField('mta_tax', StringType(), True), StructField('tip_amount', StringType(), True), StructField('tolls_amount', StringType(), True), StructField('improvement_surcharge', StringType(), True), StructField('total_amount', StringType(), True), StructField('congestion_surcharge', StringType(), True)])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f166e69-9c64-47a9-b699-ec8116f2d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('VendorID', types.IntegerType(), True), \n",
    "    types.StructField('tpep_pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('tpep_dropoff_datetime', types.TimestampType(), True), \n",
    "    types.StructField('passenger_count', types.IntegerType(), True), \n",
    "    types.StructField('trip_distance', types.DoubleType(), True), \n",
    "    types.StructField('RatecodeID', types.IntegerType(), True), \n",
    "    types.StructField('store_and_fwd_flag', types.DoubleType(), True), \n",
    "    types.StructField('PULocationID', types.IntegerType(), True), \n",
    "    types.StructField('DOLocationID', types.IntegerType(), True), \n",
    "    types.StructField('payment_type', types.IntegerType(), True), \n",
    "    types.StructField('fare_amount', types.IntegerType(), True), \n",
    "    types.StructField('extra', types.DoubleType(), True), \n",
    "    types.StructField('mta_tax', types.DoubleType(), True), \n",
    "    types.StructField('tip_amount', types.DoubleType(), True), \n",
    "    types.StructField('tolls_amount', types.IntegerType(), True), \n",
    "    types.StructField('improvement_surcharge', types.DoubleType(), True), \n",
    "    types.StructField('total_amount', types.IntegerType(), True), \n",
    "    types.StructField('congestion_surcharge', types.IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba0f30-c20c-4e44-92b1-96bb9032d9ac",
   "metadata": {},
   "source": [
    "Всего у меня 6 датасетов по месяцам 2020 года  \n",
    "Я хочу прочитать их все, а потом разбить по партициям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "979aab31-76d4-4f85-8944-939c26dc751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for month in range(1, 7):\n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(schema) \\\n",
    "        .csv(f\"data/csv/yellow_tripdata_2020-0{month}.csv\")\n",
    "\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62804198-8b79-43db-887a-1933c100d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       1| 2020-02-01 00:17:35|  2020-02-01 00:30:32|              1|          2.6|         1|              NULL|         145|           7|           1|         11|  0.5|    0.5|      2.45|           0|                  0.3|        NULL|                   0|\n",
      "|       1| 2020-02-01 00:32:47|  2020-02-01 01:05:36|              1|          4.8|         1|              NULL|          45|          61|           1|       NULL|  3.0|    0.5|       6.3|           0|                  0.3|        NULL|                NULL|\n",
      "|       1| 2020-02-01 00:31:44|  2020-02-01 00:43:28|              1|          3.2|         1|              NULL|         186|         140|           1|         11|  3.0|    0.5|       1.0|           0|                  0.3|        NULL|                NULL|\n",
      "|       2| 2020-02-01 00:07:35|  2020-02-01 00:31:39|              1|         4.38|         1|              NULL|         144|         140|           1|         18|  0.5|    0.5|       3.0|           0|                  0.3|        NULL|                NULL|\n",
      "|       2| 2020-02-01 00:51:43|  2020-02-01 01:01:29|              1|         2.28|         1|              NULL|         238|         152|           2|       NULL|  0.5|    0.5|       0.0|           0|                  0.3|        NULL|                   0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert len(dfs) == 6\n",
    "dfs[1].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27576350-9817-420b-8dfb-eacb5861e333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampType(), True), StructField('tpep_dropoff_datetime', TimestampType(), True), StructField('passenger_count', IntegerType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', IntegerType(), True), StructField('store_and_fwd_flag', DoubleType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('payment_type', IntegerType(), True), StructField('fare_amount', IntegerType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', IntegerType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', IntegerType(), True), StructField('congestion_surcharge', IntegerType(), True)])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a1e28-a6e5-4033-ba04-991570e5a6ca",
   "metadata": {},
   "source": [
    "Проверим все ли данные соотвествуют заявленным годам и месяцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42607b18-8b21-4660-b881-9c569bca8701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 223:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       2| 2021-01-02 00:22:00|  2021-01-02 00:36:50|              1|         1.56|         1|              NULL|         142|         161|           2|       NULL|  1.0|    0.5|       0.0|           0|                  0.3|        NULL|                NULL|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dfs[0].filter(dfs[0].tpep_pickup_datetime >= \"2020-01-31 23:59:59\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853ff8f-3325-448e-839d-bbbc99c0c80b",
   "metadata": {},
   "source": [
    "Есть данные выбивающиеся из диапазона отфильтруем их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7d3c0c16-d0a8-4a6e-a0e4-9aae26e70347",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [31, 29, 31, 30, 31, 30] # кол-во дней в месяцах\n",
    "\n",
    "for month in range(1, 7):\n",
    "    i = month - 1\n",
    "    \n",
    "    start_date = f\"2020-0{month}-01 00:00:00\"\n",
    "    end_date = f\"2020-0{month}-{days[i]} 23:59:59\"\n",
    "    \n",
    "    dfs[i] = dfs[i].filter(\n",
    "        (dfs[i].tpep_pickup_datetime >= start_date) & \n",
    "        (dfs[i].tpep_dropoff_datetime <= end_date)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2bc73a-aa16-489d-a7ec-047c081cf520",
   "metadata": {},
   "source": [
    "Выведем минимальную и максимальную дату для каждого датасета для проверки корректности данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09355b56-31d0-4031-aeed-fcda3c6d9833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 1\n",
      "Min date: Row(min(tpep_pickup_datetime)=datetime.datetime(2020, 1, 1, 0, 0))\n",
      "Max date: Row(max(tpep_pickup_datetime)=datetime.datetime(2020, 1, 31, 23, 59, 7))\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 2\n",
      "Min date: Row(min(tpep_pickup_datetime)=datetime.datetime(2020, 2, 1, 0, 0))\n",
      "Max date: Row(max(tpep_pickup_datetime)=datetime.datetime(2020, 2, 29, 23, 58, 40))\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 3\n",
      "Min date: Row(min(tpep_pickup_datetime)=datetime.datetime(2020, 3, 1, 0, 0))\n",
      "Max date: Row(max(tpep_pickup_datetime)=datetime.datetime(2020, 3, 31, 23, 58, 13))\n",
      "\n",
      "Month 4\n",
      "Min date: Row(min(tpep_pickup_datetime)=datetime.datetime(2020, 4, 1, 0, 0))\n",
      "Max date: Row(max(tpep_pickup_datetime)=datetime.datetime(2020, 4, 30, 23, 56, 49))\n",
      "\n",
      "Month 5\n",
      "Min date: Row(min(tpep_pickup_datetime)=datetime.datetime(2020, 5, 1, 0, 0))\n",
      "Max date: Row(max(tpep_pickup_datetime)=datetime.datetime(2020, 5, 31, 23, 54, 26))\n",
      "\n",
      "Month 6\n",
      "Min date: Row(min(tpep_pickup_datetime)=datetime.datetime(2020, 6, 1, 0, 0))\n",
      "Max date: Row(max(tpep_pickup_datetime)=datetime.datetime(2020, 6, 30, 23, 54))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for month in range(1, 7):\n",
    "    i = month - 1\n",
    "\n",
    "    min_date = dfs[i].agg({\"tpep_pickup_datetime\": \"min\"}).collect()[0]\n",
    "    max_date = dfs[i].agg({\"tpep_pickup_datetime\": \"max\"}).collect()[0]\n",
    "    \n",
    "    print(f\"Month {month}\")\n",
    "    print(f\"Min date: {min_date}\")\n",
    "    print(f\"Max date: {max_date}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31472e59-b6f2-4e26-8d0d-da4f95565ab9",
   "metadata": {},
   "source": [
    "## Преобразования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61d2f3d-7aa2-425c-8fb0-c5c3533b6596",
   "metadata": {},
   "source": [
    "- [x] Введем колонку `trip_duration_sec = tpep_dropoff_datetime - tpep_pickup_datetime` в секундах\n",
    "- [x] Отсортируем каждый датафрейм по `tpep_pickup_datetime` asc, а затем по `trip_duration_sec` desc\n",
    "- [x] Сгруппируем по всем датасетам по `PULocationID` и `tpep_pickup_datetime` и посчитаем сумму `Passenger_count`, среднее `Trip_distance`, среднее `Tip_amount`. Затем сохраним, как партицию\n",
    "- [x] Такую же группировку для `DOLocationID`, `tpep_dropoff_datetime`\n",
    "- [x] Сджоиним датасеты с датасетом `taxi+_zone_lookup.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec37b003-e121-4651-8e3a-01ef8c86a9be",
   "metadata": {},
   "source": [
    "### Колонка trip_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15b01dcf-0790-4eaf-af6d-5e5136485d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(1, 7):\n",
    "    i = month - 1\n",
    "\n",
    "    dfs[i] = dfs[i] \\\n",
    "    .withColumn(\"trip_duration_sec\", dfs[i].tpep_dropoff_datetime.cast(\"long\") - dfs[i].tpep_pickup_datetime.cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f6c2b8d-302b-48d6-9c8f-871578bebaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+-----------------+\n",
      "|tpep_dropoff_datetime|tpep_pickup_datetime|trip_duration_sec|\n",
      "+---------------------+--------------------+-----------------+\n",
      "|  2020-01-01 00:33:03| 2020-01-01 00:28:15|              288|\n",
      "|  2020-01-01 00:43:04| 2020-01-01 00:35:39|              445|\n",
      "|  2020-01-01 00:53:52| 2020-01-01 00:47:41|              371|\n",
      "|  2020-01-01 01:00:14| 2020-01-01 00:55:23|              291|\n",
      "|  2020-01-01 00:04:16| 2020-01-01 00:01:58|              138|\n",
      "+---------------------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs[0] \\\n",
    "    .select(['tpep_dropoff_datetime', 'tpep_pickup_datetime', 'trip_duration_sec']) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f771235-a923-47f0-8904-0b7a854e20d8",
   "metadata": {},
   "source": [
    "### Сортировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cf8fe0c3-29f1-4d87-b620-d9055138668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(1, 7):\n",
    "    i = month - 1\n",
    "\n",
    "    dfs[i] = dfs[i] \\\n",
    "        .orderBy(dfs[i].tpep_pickup_datetime.asc(), dfs[i].trip_duration_sec.desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1832f57d-770e-4910-9fba-c32a31bdd3c4",
   "metadata": {},
   "source": [
    "### Группировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "690312fe-2a34-4262-8db7-68254b5b09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = reduce(DataFrame.unionAll, dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9be3d-8302-44f8-bb68-f80610cc3207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91315c01-7ffc-4417-b91e-f124b850d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert df_all.count() == sum(dfs[i].count() for i in range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b5648930-454c-47b5-9947-fc966de072ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.createOrReplaceTempView('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cd740c93-47e4-4c9c-a23b-d12b263b6b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge',\n",
       " 'trip_duration_sec']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52ba80ba-b1ad-4a20-ae16-35b2afcb0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pick_up_info = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    PULocationID,\n",
    "    DATE_TRUNC('day', tpep_pickup_datetime) as pickup_date,\n",
    "    SUM(Passenger_count) as passenger_sum,\n",
    "    AVG(Trip_distance) as avg_trip_distance,\n",
    "    AVG(Tip_amount) as avg_tip_amount\n",
    "\n",
    "FROM\n",
    "    data\n",
    "\n",
    "GROUP BY\n",
    "    PULocationID, DATE_TRUNC('day', tpep_pickup_datetime)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "74972998-639c-4372-a134-76b3cb9afbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_off_info = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    DOLocationID,\n",
    "    DATE_TRUNC('day', tpep_dropoff_datetime) as dropoff_date,\n",
    "    SUM(Passenger_count) as passenger_sum,\n",
    "    AVG(Trip_distance) as avg_trip_distance,\n",
    "    AVG(Tip_amount) as avg_tip_amount\n",
    "\n",
    "FROM\n",
    "    data\n",
    "\n",
    "GROUP BY\n",
    "    DOLocationID, DATE_TRUNC('day', tpep_dropoff_datetime)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a0b63-604d-4666-893b-226c4a62d0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8dfbcec1-ebe5-40e5-9bda-5ef4409eb6a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/11 20:35:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:35:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:05 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pick_up_info \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet(\"data/parquet/prepared/pickup_2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "966b45e7-682c-41a3-8a0d-dcbeb8677a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/11 20:36:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/11 20:36:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_drop_off_info \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet(\"data/parquet/prepared/dropoff_2020\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36abd06d-6a84-49fe-beda-0b8289314a20",
   "metadata": {},
   "source": [
    "### Слияние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aa05c121-4693-4265-b1bd-67b6fe53c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"data/csv/taxi+_zone_lookup.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0750f9d8-dacb-4409-9f44-b141e41c8ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_zone_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "92600746-0e22-45c5-bdb2-b9fe3a056334",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(1, 7):\n",
    "    i = month - 1\n",
    "    \n",
    "    dfs[i] = dfs[i] \\\n",
    "        .join(taxi_zone_df, dfs[i].PULocationID == taxi_zone_df.LocationID, how='left') \\\n",
    "        .drop(\"LocationID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293a2aa-91fb-425f-8703-2596aeb4eb1f",
   "metadata": {},
   "source": [
    "## Выгрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e16f5-efe5-4d2b-98a7-04f84e4956ec",
   "metadata": {},
   "source": [
    "Теперь разобьем датасет на партиции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1de59106-7532-460f-90bc-88167cbc8c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/11 20:51:12 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/11/11 20:51:18 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/11/11 20:51:19 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/11/11 20:52:40 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/11/11 20:52:48 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/11/11 20:52:48 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/11/11 20:53:30 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/11/11 20:53:34 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/11/11 20:53:34 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/11/11 20:53:39 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/11/11 20:53:44 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/11/11 20:53:50 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for month in range(1, 7):\n",
    "    i = month - 1\n",
    "    \n",
    "    output_path = f\"data/parquet/2020/0{month}\"\n",
    "    \n",
    "    dfs[i] \\\n",
    "        .repartition(10) \\\n",
    "        .write.parquet(output_path, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bc9d017e-93c0-40b5-89fd-68d6e95959c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m01\u001b[m\u001b[m \u001b[1m\u001b[36m02\u001b[m\u001b[m \u001b[1m\u001b[36m03\u001b[m\u001b[m \u001b[1m\u001b[36m04\u001b[m\u001b[m \u001b[1m\u001b[36m05\u001b[m\u001b[m \u001b[1m\u001b[36m06\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls data/parquet/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "80b0c85b-ebf7-431a-b375-f36ce358224b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\n",
      "part-00000-1ac59635-79e5-4ec2-aef5-22b52f848a02-c000.snappy.parquet\n",
      "part-00001-1ac59635-79e5-4ec2-aef5-22b52f848a02-c000.snappy.parquet\n",
      "part-00002-1ac59635-79e5-4ec2-aef5-22b52f848a02-c000.snappy.parquet\n",
      "part-00003-1ac59635-79e5-4ec2-aef5-22b52f848a02-c000.snappy.parquet\n",
      "part-00004-1ac59635-79e5-4ec2-aef5-22b52f848a02-c000.snappy.parquet\n",
      "part-00005-1ac59635-79e5-4ec2-aef5-22b52f848a02-c000.snappy.parquet\n",
      "part-00006-1ac59635-79e5-4ec2-aef5-22b52f848a02-c000.snappy.parquet\n",
      "part-00007-1ac59635-79e5-4ec2-aef5-22b52f848a02-c000.snappy.parquet\n",
      "part-00008-1ac59635-79e5-4ec2-aef5-22b52f848a02-c000.snappy.parquet\n",
      "part-00009-1ac59635-79e5-4ec2-aef5-22b52f848a02-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls data/parquet/2020/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429295d-7537-4b3c-beaa-e97c9007b5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
